{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "problemset_MLProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "93eb259384ccf2bcbbf5dc67d78e51a41bc3a8a192fd75a7646ba938771272a8"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fxt7Jeubh0h"
      },
      "source": [
        "#https://www.tensorflow.org/tutorials/keras/classification\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ1-rWDubjvC"
      },
      "source": [
        "\n",
        "#define the model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10),\n",
        "    keras.layers.Softmax()\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuGzt2Iub6P5"
      },
      "source": [
        "# compile the keras model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cSPwptbcSV4",
        "outputId": "85793140-f4f6-403d-8da9-c1cb4dae495f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Extract the MNIST images and labels\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "img_rows, img_cols, channels = 28, 28, 1\n",
        "num_classes = 10\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "print(\"Data shapes\", x_test.shape, y_test.shape, x_train.shape, y_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOcOkc4McUOQ",
        "outputId": "56acc116-8450-4579-a18d-816a122341a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# fit the keras model on the dataset\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=5,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "# evaluate the keras model\n",
        "train_loss, train_acc = model.evaluate(x_train,  y_train, verbose=2)\n",
        "# evaluate the keras model\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTrain accuracy:', train_acc)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpU15vXrgjb_"
      },
      "source": [
        "\n",
        "test_predictions = model.predict(x_test)\n",
        "train_predictions = model.predict(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA7KKHQ9gBnG",
        "outputId": "f7ec45b0-4790-4dc2-b535-243bdebc4c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "class_names = ['Zero','One','Two','Three','Four','Five','Six','Seven','Eight','Nine']\n",
        "\n",
        "def display_images(images, predicted_labels, true_labels):\n",
        "  '''\n",
        "  Display the images in an orderly way that associates it with its predicted and true labels.\n",
        "  :images: the input images\n",
        "  :predicted_labels: the predicted labels from the model\n",
        "  :true_labels: the correct labels\n",
        "  '''\n",
        "    n = 10  # How many digits we will display\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # Display original\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(images[i].reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        predicted_label = np.argmax(predicted_labels[i])\n",
        "\n",
        "        if predicted_label == true_labels[i]:\n",
        "          color = 'blue'\n",
        "        else:\n",
        "          color = 'red'\n",
        "\n",
        "        plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                      100*np.max(predicted_labels[i]),\n",
        "                                      class_names[true_labels[i]]),\n",
        "                                      color=color)\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "display_images(x_test, test_predictions, y_test)\n",
        "display_images(x_train, train_predictions, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W1SzxTii78V"
      },
      "source": [
        "Now, create an FGSM adversarial attack function that perturbs the data using the formula\n",
        "$$\\text{Untargeted: }x' = x + \\epsilon.sign(\\nabla_xl(x,y))$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8zBEhRJi7mR"
      },
      "source": [
        "#Define the categorical cross-entropy loss object\n",
        "loss_object = keras.losses.CategoricalCrossentropy(from_logits=True )\n",
        "\n",
        "def single_adversarial_attack(input_image, input_label, eps):\n",
        "  '''\n",
        "  Produce a single-step adversarial attack on a single image\n",
        "  :input_image: the image being attacked\n",
        "  :input_label: the correct label for the image\n",
        "  :eps: a hyperparameter\n",
        "  '''\n",
        "  #Recast the image as a tensor of the proper size and datatype\n",
        "  input_image = tf.cast(input_image.reshape((1, img_rows, img_cols, channels)), tf.float32)\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(input_image)\n",
        "\n",
        "    #Get the predicted output of the i\n",
        "    prediction = tf.transpose(model(input_image))\n",
        "    input_label = input_label.reshape((input_label.shape[0],1))\n",
        "    #Get the loss between the true and predicted label\n",
        "    loss = loss_object(input_label, prediction)\n",
        "\n",
        "  # Get the gradients of the loss w.r.t to the input image.\n",
        "  gradient = tape.gradient(loss, input_image)\n",
        "\n",
        "  # Get the sign of the gradients to create the perturbation\n",
        "  signed_grad = tf.sign(gradient)\n",
        "\n",
        "\n",
        "  output = input_image + signed_grad*eps\n",
        "  \n",
        "\n",
        "  return tf.reshape(output,(img_rows, img_cols))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDpKOKyClnRq"
      },
      "source": [
        "def adversarial_attack(images, labels, eps):\n",
        "  '''\n",
        "  Perform a single-step adversarial attack on an entire dataset\n",
        "  :images: the input images\n",
        "  :labels: the true labels for the inputs\n",
        "  :eps: a hyperparameter\n",
        "  '''\n",
        "  adv_images = []\n",
        "  for x, y in zip(images, labels):\n",
        "    adv_images.append(single_adversarial_attack(x,y,eps).numpy())\n",
        "\n",
        "  return np.asarray(adv_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-9kdqQquoR7"
      },
      "source": [
        "y_train_categorical = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test_categorical = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7wBWKAAjlzH",
        "outputId": "c6aac06d-1534-4897-bbda-eaa0a8fa23b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "image = x_train[0]\n",
        "label = y_train_categorical[0].reshape(y_train_categorical[0].shape[0],1)\n",
        "x_adv = single_adversarial_attack(image, label, 0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzbdwMrrwqxs",
        "outputId": "a26b6163-5989-438b-ddef-9c040b7de35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.imshow(x_adv)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr4imrAwl_t9"
      },
      "source": [
        "#Create an attack on the training data\n",
        "attack_imgs = adversarial_attack(x_train, y_train_categorical, 0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBv0pK7Fwb8M",
        "outputId": "ceda5eef-8e70-4acd-8bc7-3284fe2da156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Base accuracy on adversarial images:\", model.evaluate(x=attack_imgs, y=y_train, verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujjCXM_qGdA"
      },
      "source": [
        "adv_train_predictions = model.predict(attack_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyMOiYa_s4Ok",
        "outputId": "83eb7e51-84f7-4c25-ac19-7d2fc7890836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "display_images(attack_imgs, adv_train_predictions, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqsF2h5euTTg"
      },
      "source": [
        "Now implement a multi-step untargeted PGD adversarial attack using the formula:\n",
        "$$\\text{Untargeted: }x_0' = x \\implies x_{N+1}' = Clip_{x,\\epsilon}\\{x_N' + \\alpha.sign(\\nabla_xl(x_n', y)\\} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oCsShGXuuUv"
      },
      "source": [
        "\n",
        "\n",
        "def single_multistep_adversarial_attack(input_image, input_label, eps, a, T):\n",
        "  '''\n",
        "  Produce a multi-step adversarial attack on a single image\n",
        "  :input_image: the image being attacked\n",
        "  :input_label: the correct label for the image\n",
        "  :eps: a hyperparameter\n",
        "  :a: another hyperparameter defining the step size\n",
        "  :T: the number of steps to be taken\n",
        "  '''\n",
        "\n",
        "  image_temp = tf.cast(input_image.reshape((1, img_rows, img_cols, channels)), tf.float32)\n",
        "      \n",
        "      \n",
        "  for t in range(T):\n",
        "    #Define the step size\n",
        "    step_size = (1 - a*t)**(-1)\n",
        "      \n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(image_temp)\n",
        "\n",
        "      #Predict the label of the image\n",
        "      prediction = tf.transpose(model(image_temp))\n",
        "      input_label = input_label.reshape((input_label.shape[0],1))\n",
        "      #Calculate the loss between the true label and the prediction\n",
        "      loss = loss_object(input_label, prediction)\n",
        "\n",
        "    # Get the gradients of the loss w.r.t to the input image.\n",
        "    gradient = tape.gradient(loss, image_temp)\n",
        "\n",
        "    # Get the sign of the gradients to create the perturbation\n",
        "    signed_grad = tf.sign(gradient)\n",
        "\n",
        "    image_temp = image_temp + signed_grad*step_size\n",
        "\n",
        "\n",
        "  return tf.reshape(image_temp, [img_rows, img_cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jbhqM8TaKRi"
      },
      "source": [
        "def multistep_adversarial_attack(images, labels, eps, a, T):\n",
        "  '''\n",
        "  Perform multi-step adversarial attacks on an entire dataset\n",
        "  :images: the images being attacked\n",
        "  :labels: the correct labels for the images\n",
        "  :eps: a hyperparameter\n",
        "  :a: another hyperparameter defining the step size\n",
        "  :T: the number of steps to be taken\n",
        "  '''\n",
        "  adv_images = []\n",
        "  for i, (x, y) in enumerate(zip(images, labels)):\n",
        "    adv_images.append(single_multistep_adversarial_attack(x,y,eps, a, T).numpy())\n",
        "\n",
        "  return np.asarray(adv_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G7ZHgku6kML"
      },
      "source": [
        "multistep_attack = single_multistep_adversarial_attack(x_train[0], y_train_categorical[0], 0.1, 0.01, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yU0osI67x0w",
        "outputId": "32e55ef8-0628-4030-a96f-d6e624488707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.imshow(multistep_attack)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbfcb8zsaTWR",
        "outputId": "77a1ae4a-2dd2-4a15-d6f3-5167b79885d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "multistep_attack_images = multistep_adversarial_attack(x_train[0:300], y_train_categorical[0:300], 0.1, 0.001, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwUcmr7eafYU",
        "outputId": "a0d912a2-ce19-4996-a5a4-5346394431de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Base accuracy on adversarial images:\", model.evaluate(x=multistep_attack_images, y=y_train[0:300], verbose=0))\n",
        "adv_train_predictions = model.predict(multistep_attack_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIBnTegEvSpw",
        "outputId": "5106907e-91bc-4673-942f-790de4f254ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "display_images(multistep_attack_images, adv_train_predictions, y_train[0:300])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}